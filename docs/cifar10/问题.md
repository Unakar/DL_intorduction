# 疑问解答
特征工程：对数据(图像，音频转化tensor，标准化，Augmentation等)进行预处理，以便于模型更好的学习到数据的特征。
X: (x-x.mean)/x.std,数据增强


softmax:将输出转化为概率分布，使得输出的概率和为1。

conv2d参数：输入通道数，输出通道数，卷积核大小(kernel)
encoder高维向量空间的一组基为kernel 3*3，5*5，7*7

relu(x) = max(0,x)
leakyRelu(x) = max(0.01x,x)

optimizer:优化器，用于更新模型参数，使得loss最小。SGD随机梯度下降
criterian: MSELoss: (y_hat - y)^2,交叉熵损失 CrossEntropyLoss ,KL散度损失 KLDivLoss
p,q两个分布的KL散度：D_kl(p||q) = sum(p(x)log(p(x)/q(x)))
卷积等价于一个全连接层，但是参数共享，减少了参数数量。

权重初始化：Kaiming initialize

Dataloader:
     sampler: indice
     dataset: data

# Q1:batch_size的大小如何选择？是否越大越好？
大的batch可能导致模型更容易收敛局部在最优解，而不是全局最优；
大的batch使得模型总更新次数变少了，可能导致模型收敛速度变慢；显存不够

# Q2:归纳偏置 inductive bias（为什么我的网络可以学习到图像信息）
先验假设：卷积层的参数共享，使得网络可以学习到图像的局部特征，而不是整体特征。
深度神经网络：层次化处理信息，使得网络可以学习到图像的抽象特征。
卷积神经网络CNN：信息具有空间局部性
反馈神经网络RNN：信息具有时序性，强调顺序的重要性
图神经网络GNN：认为图中心节点与周围节点的相邻关系可以决定信息流动

# Q3: 先验知识注入深度学习过程
1. 网络结构就是先验知识
2. 网络权重是先验，imagnet预训练权重baseline model(固定上层模型权重，只改变全连接层参数做更新)
3. 数据增强注入先验知识
4. 训练过程中的正则化（惩罚项）L1,L2,

# Q4:如何对baseline model做优化，使其性能增长



